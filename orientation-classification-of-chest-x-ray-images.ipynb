{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d2cf1ec",
   "metadata": {
    "papermill": {
     "duration": 0.004065,
     "end_time": "2024-01-04T06:11:21.849762",
     "exception": false,
     "start_time": "2024-01-04T06:11:21.845697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Classify Orientations \n",
    "## Given images are rotated and we need to classify the direction in which they are facing\n",
    "## To do so, we are going to use the ResNet18 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55856834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:21.858608Z",
     "iopub.status.busy": "2024-01-04T06:11:21.858054Z",
     "iopub.status.idle": "2024-01-04T06:11:26.985633Z",
     "shell.execute_reply": "2024-01-04T06:11:26.984836Z"
    },
    "papermill": {
     "duration": 5.134362,
     "end_time": "2024-01-04T06:11:26.987883",
     "exception": false,
     "start_time": "2024-01-04T06:11:21.853521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import ToTensor, Compose, Resize, Grayscale, Normalize, Lambda\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe93829f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:26.996950Z",
     "iopub.status.busy": "2024-01-04T06:11:26.996572Z",
     "iopub.status.idle": "2024-01-04T06:11:27.003800Z",
     "shell.execute_reply": "2024-01-04T06:11:27.002893Z"
    },
    "papermill": {
     "duration": 0.013752,
     "end_time": "2024-01-04T06:11:27.005671",
     "exception": false,
     "start_time": "2024-01-04T06:11:26.991919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a custom class for dataset \n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        image = T.ToPILImage() (image)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e97cc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:27.013866Z",
     "iopub.status.busy": "2024-01-04T06:11:27.013594Z",
     "iopub.status.idle": "2024-01-04T06:11:27.017380Z",
     "shell.execute_reply": "2024-01-04T06:11:27.016644Z"
    },
    "papermill": {
     "duration": 0.010029,
     "end_time": "2024-01-04T06:11:27.019200",
     "exception": false,
     "start_time": "2024-01-04T06:11:27.009171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49041c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:27.027810Z",
     "iopub.status.busy": "2024-01-04T06:11:27.027162Z",
     "iopub.status.idle": "2024-01-04T06:11:27.055920Z",
     "shell.execute_reply": "2024-01-04T06:11:27.055275Z"
    },
    "papermill": {
     "duration": 0.035064,
     "end_time": "2024-01-04T06:11:27.057837",
     "exception": false,
     "start_time": "2024-01-04T06:11:27.022773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the transform for loading the data\n",
    "transform = Compose([\n",
    "    ToTensor(),\n",
    "    Lambda(lambda x: x.repeat(3,1,1)),\n",
    "    Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Define the training image directory and annotations csv\n",
    "directions01_train_img_dir = '/kaggle/input/chestxraydirections01/dataset/Directions01'\n",
    "directions01_train_annotations_file = '/kaggle/input/chestxraydirections01/dataset/Directions01/list_train.txt'\n",
    "\n",
    "# Defining the training dataset and data loader\n",
    "directions_train_dataset = CustomDataset(\n",
    "    annotations_file=directions01_train_annotations_file,\n",
    "    img_dir=directions01_train_img_dir,\n",
    "    transform=transform,\n",
    ")\n",
    "directions_train_dataloader = DataLoader(directions_train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the testing image directory and annotations csv\n",
    "directions01_test_img_dir = '/kaggle/input/chestxraydirections01/dataset/Directions01'\n",
    "directions01_test_annotations_file = '/kaggle/input/chestxraydirections01/dataset/Directions01/list_test.txt'\n",
    "\n",
    "# Defining the testing dataset and data loader\n",
    "directions_test_dataset = CustomDataset(\n",
    "    annotations_file=directions01_test_annotations_file,\n",
    "    img_dir=directions01_test_img_dir,\n",
    "    transform=transform\n",
    ")\n",
    "directions_test_loader = DataLoader(directions_test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f3719c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:27.066320Z",
     "iopub.status.busy": "2024-01-04T06:11:27.065697Z",
     "iopub.status.idle": "2024-01-04T06:11:27.071650Z",
     "shell.execute_reply": "2024-01-04T06:11:27.070848Z"
    },
    "papermill": {
     "duration": 0.012164,
     "end_time": "2024-01-04T06:11:27.073566",
     "exception": false,
     "start_time": "2024-01-04T06:11:27.061402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definining the resnet18 model\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "class Resnet18Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Resnet18Classifier, self).__init__()\n",
    "        self.resnet18 = resnet18(pretrained=False).eval()\n",
    "        num_ftrs = self.resnet18.fc.in_features\n",
    "        self.resnet18.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.resnet18(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28be9852",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:27.081668Z",
     "iopub.status.busy": "2024-01-04T06:11:27.081424Z",
     "iopub.status.idle": "2024-01-04T06:11:30.643654Z",
     "shell.execute_reply": "2024-01-04T06:11:30.642725Z"
    },
    "papermill": {
     "duration": 3.568951,
     "end_time": "2024-01-04T06:11:30.646045",
     "exception": false,
     "start_time": "2024-01-04T06:11:27.077094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnet18Classifier(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the resnet18 classifier with number of output models\n",
    "num_classes = 4\n",
    "resnet_18_classifier = Resnet18Classifier(num_classes).to(device)\n",
    "\n",
    "# Defining the loss_function and the optimizer\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet_18_classifier.parameters(), lr = 0.001)\n",
    "resnet_18_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23464e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:30.655198Z",
     "iopub.status.busy": "2024-01-04T06:11:30.654904Z",
     "iopub.status.idle": "2024-01-04T06:11:30.659131Z",
     "shell.execute_reply": "2024-01-04T06:11:30.658287Z"
    },
    "papermill": {
     "duration": 0.010901,
     "end_time": "2024-01-04T06:11:30.661018",
     "exception": false,
     "start_time": "2024-01-04T06:11:30.650117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the label mapping for each direction\n",
    "label_mapping = {\n",
    "    'left': 0,\n",
    "    'right': 1,\n",
    "    'up': 2,\n",
    "    'down': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89d77b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:30.669494Z",
     "iopub.status.busy": "2024-01-04T06:11:30.669192Z",
     "iopub.status.idle": "2024-01-04T06:11:56.440894Z",
     "shell.execute_reply": "2024-01-04T06:11:56.439636Z"
    },
    "papermill": {
     "duration": 25.778593,
     "end_time": "2024-01-04T06:11:56.443326",
     "exception": false,
     "start_time": "2024-01-04T06:11:30.664733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.7017\n",
      "Epoch [2/10], Loss: 1.6169\n",
      "Epoch [3/10], Loss: 1.2916\n",
      "Epoch [4/10], Loss: 0.0690\n",
      "Epoch [5/10], Loss: 0.1052\n",
      "Epoch [6/10], Loss: 0.0010\n",
      "Epoch [7/10], Loss: 0.2102\n",
      "Epoch [8/10], Loss: 0.0293\n",
      "Epoch [9/10], Loss: 0.0002\n",
      "Epoch [10/10], Loss: 0.0004\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in directions_train_dataloader:\n",
    "        numeric_labels = [label_mapping[label] for label in labels]\n",
    "        numeric_labels_tensor = torch.tensor(numeric_labels)\n",
    "        images, labels = images.to(device), numeric_labels_tensor.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet_18_classifier(images)\n",
    "#         print(f'Output is {outputs}')\n",
    "#         print(f'Labels are {labels}')\n",
    "        loss = loss_func(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d7ba2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-04T06:11:56.455153Z",
     "iopub.status.busy": "2024-01-04T06:11:56.454828Z",
     "iopub.status.idle": "2024-01-04T06:11:56.662252Z",
     "shell.execute_reply": "2024-01-04T06:11:56.661210Z"
    },
    "papermill": {
     "duration": 0.215712,
     "end_time": "2024-01-04T06:11:56.664335",
     "exception": false,
     "start_time": "2024-01-04T06:11:56.448623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for directions: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "correct = 0\n",
    "total = 0\n",
    "# Don't calculate gradients during evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in directions_test_loader:\n",
    "        numeric_labels = [label_mapping[label] for label in labels]\n",
    "        numeric_labels_tensor = torch.tensor(numeric_labels)\n",
    "        images, labels = images.to(device), numeric_labels_tensor.to(device)\n",
    "        outputs = resnet_18_classifier(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        # print(f'Run for instance {total} and {correct}')\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy for directions: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e787a90",
   "metadata": {
    "papermill": {
     "duration": 0.004526,
     "end_time": "2024-01-04T06:11:56.673572",
     "exception": false,
     "start_time": "2024-01-04T06:11:56.669046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Achieved 100% accuracy with Resnet50 for classifying image directions."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3923076,
     "sourceId": 6821029,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40.670264,
   "end_time": "2024-01-04T06:11:58.975130",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-04T06:11:18.304866",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
